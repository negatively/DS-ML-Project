# -*- coding: utf-8 -*-
"""music_recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZLfXg2B597BRnNLXgpxZfiHdeL2ivjnT

# Sistem Rekomendasi Musik Spotify
**Oleh : Yoga Mileniandi**

## Pendahuluan
![spotify](https://user-images.githubusercontent.com/61934759/137764151-d27729b5-7145-4df8-97e2-168e7bbb0caf.png)
Proyek berupa sistem rekomendasi musik yang ditunjukkan bagi pengguna aplikasi Spotify. Sistem rekomendasi musik ini menggunakan pendekatan content-based filtering. Content-based filtering melakukan rekomendasi dengan mempelajari profil minat pengguna baru berdasarkan data dari objek yang telah dinilai pengguna.

## 1. Mempersiapkan Library dan Dataset

### 1.1 Memanggil Library
"""

# Library untuk pengolahan data
import numpy as np
import pandas as pd
from zipfile import ZipFile
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_extraction.text import TfidfVectorizer

# Library untuk visualisasi data
import matplotlib.pyplot as plt
import seaborn as sns

# Library untuk pemodelan
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import calinski_harabasz_score

"""### 1.2 Mengunduh Dataset from Kaggle"""

# Melakukan pengaturan API Kaggle
! pip install -q kaggle
from google.colab import files
files.upload()
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

# Mengambil dataset dari Kaggle
!kaggle datasets download -d edalrami/19000-spotify-songs

"""### 1.3 Memuat dataset"""

# Ekstrasi data
path = '/content/19000-spotify-songs.zip'
with ZipFile(path, 'r') as zip_ref:
  zip_ref.extractall('working')

# Memuat dataset dengan library pandas
song_info = pd.read_csv("/content/working/song_info.csv")

"""## 2. Pemahaman Data

Data yang digunakan untuk proyek kali ini adalah 19,000 Spotify Song yang diunduh dari [Dataset Kaggle](https://www.kaggle.com/edalrami/19000-spotify-songs/code). Dataset tersebut memiliki dua buah file berformat csv, yaitu _song_data.csv_ dan _song_info.csv_. _song_data.csv_ berisi informasi yang berkaitan tentang atribut audio lagu. Sedangkan _song_info.csv_ berisi informasi yang berkaitan tentang metadata lagu.
"""

# Melihat isi song_info
song_info.head()

song_info.info()

"""Untuk penjelasan tentang variabel-variabel kolom tersebut, dapat dilihat pada poin-poin berikut :
* `song_name` : Judul lagu yang tertampil
* `artist_name` : Nama penyanyi yang menyanyikan lagu tersebut
* `album_names` : Nama album dimana lagu tersebut termasuk sebagai koleksinya, album sendiri adalah koleksi lagu dari suatu penyanyi
* `playlist` : Kumpulan lagu yang memiliki suatu kesamaan

## 3. Eksplorasi Data
Kemudian dilakukan juga eksplorasi data dan visualisasi tentang kolomnya.
"""

# Melihat jumlah lagu yang ada pada dataset
print("Jumlah lagu yang ada dalam dataset : ", len(song_info.song_name.unique()))

# Melihat jumlah artis yang ada pada dataset
print("Jumlah Penyanyi dalam dataset : ", len(song_info.artist_name.unique()))

# Melihat jumlah album dalam dataset
print("Jumlah Album dalam dataset : ", len(song_info.album_names.unique()))

# Melihat jumlah playlist dalam dataset
print("Jumlah Playlist dalam dataset : ", len(song_info.playlist.unique()))

# To 10 Penyayi dengan lagu terbanyak
plt.figure(figsize=(12,8))
sns.countplot(x='artist_name', data = song_info, order = song_info.artist_name.value_counts().sort_values(ascending=False).iloc[:10].index)
plt.title("Top 10 Artist dengan Lagu Terbanyak")
plt.xticks(rotation = 45)
plt.show()

# Top 10 playlist dengan lagu terbanyak
plt.figure(figsize=(12,8))
sns.countplot(x='playlist', data=song_info, order = song_info.playlist.value_counts().sort_values(ascending=False).iloc[:10].index)
plt.title("Top 10 Playlist dengan Lagu Terbanyak")
plt.xticks(rotation = 45)
plt.show()

# Melihat adanya missing value
song_info.isna().sum()

"""## 4. Data Preparation
Tahap berikutnya adalah _data preparation_, tahap dimana data akan diolah sehingga sudah siap untuk proses pemodelan.
"""

# Membuang data duplikat duplikat
song_info = song_info.drop_duplicates(['song_name', 'artist_name'])
song_info

"""Membuang data duplikasi yang memiliki kesamaan pada kolom `song_name` dan  `artist_name`. Tujuannya supaya tidak muncul suatu data sebanyak 2 kali pada proses rekomendasi nanti. Proses penghilangan data duplikasi ini adalah dengan perintah _drop_duplicates_ dari library pandas."""

# Menggabungkan kolom artist_name, album_names, dan playlist
new_song_info = song_info.copy()
new_song_info['info'] = new_song_info[['artist_name','album_names','playlist']].agg(' '.join, axis=1) 

# Melakukan drop pada kolom artist_name, album_names, dan playlist
new_song_info = new_song_info.drop(columns=['artist_name', 'album_names', 'playlist'], axis = 1)
new_song_info.head()

"""Membuat fitur baru bernama `info` dengan cara menggabungkan kolom `artist_name`, `album_names`, dan `playlist`. Hal tersebut dilakukan untuk memudahkan proses TF-IDF, karena fitur `info` telah mencakup ketiga fitur kolom.

## 5. Pemodelan dan Hasil
Setelah data telah diolah, maka proses selanjutnya adalah pemodelan. Dalam pemodelan ini data akan dilakukan proses TF-IDF dan cosine similarity

### TF-IDF
Secara sederhana TF merupakan frekuensi kemunculan kata dalam suatu dokumen. IDF merupakan sebuah perhitungan dari bagaimana kata didistribusikan secara luas pada koleksi dokumen yang bersangkutan. Pada projek ini TF-IDF digunakan pada sistem rekomendasi untuk menemukan representasi fitur penting dari setiap kategori masakan. Untuk melakukan proses TF-IDF ini digunakan fungsi _TfidfVectorizer_ dari sklearn.
"""

# Persiapan tfidfvectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada kolom info
tf.fit(new_song_info['info'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

# Melakukan fit lagu di translasikan ke bentuk matriks
tfidf_matrix = tf.fit_transform(new_song_info['info'])

# Melihat ukuran matriks
tfidf_matrix.shape

tfidf_matrix.todense()

"""### Cosine Similarity
_Cosine similarity_ adalah metrik yang digunakan untuk mengukur tingkat kesamaan suatu dokumen terlepas dari ukurannya. Dan secara matematis, _cosine similarity_ mengukur kosinus sudut antara dua vektor yang diproyeksikan dalam ruang multidimensi. _Cosine similarity_ memiliki keuntungan apabila dua dokumen serupa terpisah oleh _euclidean distance_ karena ukuran dokumen, kemungkinan mereka masih berorientasi ada. Dalam proses ini _cosine similarity_ dipanggil dengan fungsi _cosine_similarity_ dari sklearn. Input fungsi _cosine_similarity_ adalah matrix hasil dari proses TF-IDF, yang kemudian menghasilkan output berupa array tingkat kesamaan.
"""

# Menghitung cosine similarity
cos_sim = cosine_similarity(tfidf_matrix)
cos_sim

# Membuat dataframe dari variabel cos_sim dengan baris dan kolom berupa song_name
cos_sim_df = pd.DataFrame(cos_sim, index=new_song_info['song_name'], columns=new_song_info['song_name'])
print('Shape:', cos_sim_df.shape)

"""### Fungsi Rekomendasi
ungsi tersebut digunakan untuk memberikan rekomendasi berdasarkan sebuah nama lagu. Pada fungsi tersebut akan dilakukan pencarian kolom  yang sama dengan nama lagu yang dimasukkan pada dataframe hasil _cosine similarity_. Setelah itu diurutkan berdasarkan nilai _cosine similarity_ tertinggi, kemudian dilakukan _drop_ nama lagu yang dijadikan acuan agar tidak muncul dalam daftar rekomendasi. Kemudian outputnya berupa 5 lagu yang memiliki cosine similarity tertinggi.
"""

def song_recommendations(song_name, similarity_data=cos_sim_df, items=song_info, k=5): 
  print(f"Jika kamu menyukai lagu {song_name}, mungkin kamu juga menyukai 5 lagu berikut :")
  # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
  index = similarity_data.loc[:,song_name].to_numpy().argpartition(range(-1, -k, -1))
    
  # Mengambil data dengan similarity terbaik
  closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
  # Drop song_name
  closest = closest.drop(song_name, errors='ignore')
 
  return pd.DataFrame(closest).merge(items).head(k)

# Melihat informasi tentang lagu yang akan dijadikan acua
song_info[song_info.song_name.eq('Rap God')]

# Mendapatkan rekomendasi musik
song_recommendations(song_name="Rap God")

"""## 6. Evaluasi

Metriks yang akan digunakan untuk evaluasi pada sistem rekomendasi ini adalah presisi. Presisi merupakan banyaknya item rekomendasi yang relevan dibagi dengan banyaknya item yang direkomendasikan. Rumus dari metriks presisi adalah sebagai berikut
![presisi](https://user-images.githubusercontent.com/61934759/138005224-8c8be6fd-58d8-4bc6-978f-d7ee5ce9c3e8.JPG)
"""

# Presisi sistem rekomendasi
relevan = 4 # Banyaknya item rekomendasi yang relevan
rekomen = 5 # Banyaknya item yang direkomendasikan
presisi = relevan / rekomen
print(f"Jadi Presisi rekomendasi yang diberikan untuk lagu 'Rap God' adalah {presisi*100}%")

"""## Referensi

* https://towardsdatascience.com/recommendation-systems-models-and-evaluation-84944a84fb8e
* https://www.kaggle.com/benroshan/content-collaborative-anime-recommendation#Recommendation-building-phase---Tsukuru-(%E4%BD%9C%E3%82%8B)
"""